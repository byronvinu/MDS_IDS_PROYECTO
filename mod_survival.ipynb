{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHASIS</th>\n",
       "      <th>TIEMPO_MANT_1000</th>\n",
       "      <th>EVENTO_MANT_1000</th>\n",
       "      <th>CENSURA</th>\n",
       "      <th>AGENCIA</th>\n",
       "      <th>LINEA_NEGOCIO</th>\n",
       "      <th>FAMILIA_VH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9BRKZAAG4S0701975</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GRANADOS</td>\n",
       "      <td>VEH. NUEVOS TOYOTA</td>\n",
       "      <td>COROLLA CROSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JTDKBABB4SA427735</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LOS CHILLOS</td>\n",
       "      <td>VEH. NUEVOS TOYOTA</td>\n",
       "      <td>YARIS CROSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JTDKBABB5SA417389</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SUR</td>\n",
       "      <td>VEH. NUEVOS TOYOTA</td>\n",
       "      <td>YARIS CROSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MHFBU3FS0S0352770</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SANTO DOMINGO</td>\n",
       "      <td>VEH. NUEVOS TOYOTA</td>\n",
       "      <td>FORTUNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8AJCB3DD2S3920542</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GRANADOS</td>\n",
       "      <td>VEH. NUEVOS TOYOTA</td>\n",
       "      <td>HILUX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CHASIS  TIEMPO_MANT_1000  EVENTO_MANT_1000  CENSURA  \\\n",
       "0  9BRKZAAG4S0701975                94                 1        0   \n",
       "1  JTDKBABB4SA427735                80                 1        0   \n",
       "2  JTDKBABB5SA417389                83                 1        0   \n",
       "3  MHFBU3FS0S0352770               101                 0        1   \n",
       "4  8AJCB3DD2S3920542               101                 0        1   \n",
       "\n",
       "         AGENCIA       LINEA_NEGOCIO      FAMILIA_VH  \n",
       "0       GRANADOS  VEH. NUEVOS TOYOTA  COROLLA CROSS   \n",
       "1    LOS CHILLOS  VEH. NUEVOS TOYOTA    YARIS CROSS   \n",
       "2            SUR  VEH. NUEVOS TOYOTA    YARIS CROSS   \n",
       "3  SANTO DOMINGO  VEH. NUEVOS TOYOTA        FORTUNER  \n",
       "4       GRANADOS  VEH. NUEVOS TOYOTA           HILUX  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lectura de datos \n",
    "from ssconnect import connect_singlestore\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "engine = connect_singlestore()\n",
    "sql=\"SELECT * FROM DWH.VW_VENTA_VS_MANTENIMIENTO WHERE FAMILIA_VH NOT IN ('NO DEFINIDO')\"\n",
    "df_prep= pd.read_sql(sql, engine)\n",
    "df_prep = df_prep[df_prep['TIPO_DOCUMENTO'] == 'FACTURA CREDITO']\n",
    "df_prep = df_prep.sort_values('FECHA', ascending=False)\n",
    "df_prep = df_prep.drop_duplicates(subset=['CHASIS'], keep='first')\n",
    "df_prep['FECHA'] = pd.to_datetime(df_prep['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "df_prep = df_prep[df_prep['FECHA'] < dt.datetime(2025, 1, 1)]\n",
    "df_prep.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convertir las columnas de fecha a tipo datetime\n",
    "df_prep['FECHA_SALIDA'] = pd.to_datetime(df_prep['FECHA_SALIDA'], format='%Y-%m-%d', errors='coerce')\n",
    "df_prep['FECHA_MNT_1000'] = pd.to_datetime(df_prep['FECHA_MNT_1000'], format='%Y-%m-%d', errors='coerce')\n",
    "df_prep['FECHA_MNT_1000_2'] = pd.to_datetime(df_prep['FECHA_MNT_1000'], format='%Y-%m-%d', errors='coerce')\n",
    "# Si FECHA_MNT_1000 es 1970-01-01 , colocar la fecha de hoy\n",
    "df_prep['FECHA_MNT_1000_2'] = df_prep['FECHA_MNT_1000_2'].where(df_prep['FECHA_MNT_1000_2'] > dt.datetime(1970, 1, 1), dt.datetime.today())\n",
    "# Calcular la diferencia en días entre LA FECHA  y el primer mantenimiento\n",
    "df_prep['TIEMPO_MANT_1000'] = (df_prep['FECHA_MNT_1000_2'] - df_prep['FECHA']).dt.days\n",
    "# Crear una columna de evento (si hubo mantenimiento o no)\n",
    "df_prep['EVENTO_MANT_1000'] = df_prep['MANTENIMIENTO_1000'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# quitar los registos con timepo mant negativos\n",
    "df_prep = df_prep[df_prep['TIEMPO_MANT_1000'] >= 0]\n",
    "# los registros que tienen mas de 120 dias hasta el primer mantenimiento se consideran censurados\n",
    "df_prep['EVENTO_MANT_1000'] = df_prep['EVENTO_MANT_1000'].where(df_prep['TIEMPO_MANT_1000'] <= 120, 0)\n",
    "\n",
    "#crear la columna de censura, si el tiempo hasta el primer mantenimiento es mayor a 120 dias se considera censurado de igual manera los que tienen fecha de mantenimiento 1970-01-01\n",
    "df_prep['CENSURA'] = df_prep['TIEMPO_MANT_1000'].apply(lambda x: 1 if x > 120 else 0)\n",
    "# los registros que tienen fecha de mantenimiento 1970-01-01 se consideran censurados   \n",
    "df_prep['CENSURA'] = df_prep['CENSURA'].where(df_prep['FECHA_MNT_1000'] > dt.datetime(1970, 1, 1), 1)\n",
    "# los registros que son iguales o mayores a 120 dias se considera que no tuvieron mantenimiento\n",
    "df_prep['TIEMPO_MANT_1000'] = df_prep['TIEMPO_MANT_1000'].where(df_prep['TIEMPO_MANT_1000'] <= 120, 120)\n",
    "# seleccionar las columnas necesarias para el analisis \n",
    "df_prep = df_prep[['CHASIS','TIEMPO_MANT_1000', 'EVENTO_MANT_1000','CENSURA', 'AGENCIA', 'LINEA_NEGOCIO', 'FAMILIA_VH']]\n",
    "df_prep.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:19:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.60      0.50      0.41      4421\n",
      "weighted avg       0.63      0.69      0.57      4421\n",
      "\n",
      "Random Forest Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.60      0.50      0.41      4421\n",
      "weighted avg       0.63      0.69      0.57      4421\n",
      "\n",
      "Gradient Boosting Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.60      0.50      0.41      4421\n",
      "weighted avg       0.63      0.69      0.57      4421\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.35      0.50      0.41      4421\n",
      "weighted avg       0.48      0.69      0.57      4421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.35      0.50      0.41      4421\n",
      "weighted avg       0.48      0.69      0.57      4421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:19:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01      1356\n",
      "           1       0.69      1.00      0.82      3065\n",
      "\n",
      "    accuracy                           0.69      4421\n",
      "   macro avg       0.60      0.50      0.41      4421\n",
      "weighted avg       0.63      0.69      0.57      4421\n",
      "\n",
      "XGBoost Accuracy: 0.6933\n",
      "Random Forest Accuracy: 0.6933\n",
      "Gradient Boosting Accuracy: 0.6933\n",
      "Logistic Regression Accuracy: 0.6933\n",
      "SVC Accuracy: 0.6933\n",
      "Voting Classifier Accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (16577, 25), y_train shape: (16577,)\n",
      "X_train_resampled shape: (23056, 25), y_train_resampled shape: (16577,)\n",
      "Estimadores: 50, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [23056, 16577, 16577]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimadores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimador\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Learning Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m gbsa \u001b[38;5;241m=\u001b[39m GradientBoostingSurvivalAnalysis(n_estimators\u001b[38;5;241m=\u001b[39mestimador, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m gbsa\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Predecir los riesgos en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m     62\u001b[0m survival_risks \u001b[38;5;241m=\u001b[39m gbsa\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sksurv/ensemble/boosting.py:1250\u001b[0m, in \u001b[0;36mGradientBoostingSurvivalAnalysis.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_state()\n\u001b[1;32m   1242\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[1;32m   1249\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m event, time \u001b[38;5;241m=\u001b[39m check_array_survival(X, y)\n\u001b[1;32m   1252\u001b[0m sample_weight_is_none \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sksurv/util.py:229\u001b[0m, in \u001b[0;36mcheck_array_survival\u001b[0;34m(X, y, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    Time of event or censoring.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m event, time \u001b[38;5;241m=\u001b[39m check_y_survival(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 229\u001b[0m check_consistent_length(X, event, time)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m event, time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [23056, 16577, 16577]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Asumiendo que df_prep ya está cargado\n",
    "# df_prep = ...\n",
    "\n",
    "# Seleccionar las variables relevantes\n",
    "df = df_prep[['TIEMPO_MANT_1000', 'EVENTO_MANT_1000', 'AGENCIA', 'FAMILIA_VH']].copy()\n",
    "df.dropna(inplace=True) # Eliminar filas con valores faltantes para simplificar\n",
    "\n",
    "# Codificación one-hot para variables categóricas\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "categorical_cols = ['AGENCIA', 'FAMILIA_VH']\n",
    "encoded_data = encoder.fit_transform(df[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Resetear el índice de df para que coincida con encoded_df después de la transformación\n",
    "df_reset = df.reset_index(drop=True)\n",
    "df_processed = pd.concat([df_reset[['TIEMPO_MANT_1000', 'EVENTO_MANT_1000']], encoded_df], axis=1)\n",
    "\n",
    "# Crear el array estructurado de supervivencia\n",
    "y = np.array(list(zip(df_processed['EVENTO_MANT_1000'], df_processed['TIEMPO_MANT_1000'])),\n",
    "             dtype=[('status', '?'), ('time', '<f8')])\n",
    "\n",
    "# Separar características (X) y variable de supervivencia (y)\n",
    "X = df_processed.drop(columns=['TIEMPO_MANT_1000', 'EVENTO_MANT_1000'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba , aplicar sobremuestreo \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Aplicar SMOTE para el sobremuestreo\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Convertir y_train_resampled a un array estructurado\n",
    "y_train_resampled = np.array(list(zip(y_train_resampled['status'], y_train_resampled['time'])),\n",
    "                             dtype=[('status', '?'), ('time', '<f8')])\n",
    "# Verificar la forma de los datos\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_train_resampled shape: {X_train_resampled.shape}, y_train_resampled shape: {y_train_resampled.shape}\")\n",
    "\n",
    "\n",
    "# Inicializar y entrenar el modelo GradientBoostingSurvivalAnalysis , crear una for que iteractue entre diferentes parametos\n",
    "estimadors=[50, 100, 200,]\n",
    "lr=[0.01,  0.1]\n",
    "c_indexes = []\n",
    "\n",
    "for estimador in estimadors:\n",
    "    for learning_rate in lr:\n",
    "        print(f\"Estimadores: {estimador}, Learning Rate: {learning_rate}\")\n",
    "        gbsa = GradientBoostingSurvivalAnalysis(n_estimators=estimador, learning_rate=learning_rate, random_state=42)\n",
    "        gbsa.fit(X_train, y_train)\n",
    "        # Predecir los riesgos en el conjunto de prueba\n",
    "        survival_risks = gbsa.predict(X_test)\n",
    "        # Calcular el índice de concordancia en el conjunto de prueba , agregar los parametros del modelo\n",
    "        c_index = concordance_index_censored(y_test['status'], survival_risks, y_test['time'])\n",
    "        c_indexes.append(c_index[0])\n",
    "        print(f\"Estimadores: {estimador}, Learning Rate: {learning_rate}, C-index: {c_index[0]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Estimadores: 50, Learning Rate: 0.01, C-index: 0.3349\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame para almacenar los resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Estimadores': [f\"{estimator}\" for estimator in estimadors for _ in range(len(lr))],\n",
    "    'Learning Rate': [f\"{learning_rate}\" for _ in estimadors for learning_rate in lr],\n",
    "    'C-index': c_indexes\n",
    "})\n",
    "results_df = results_df.sort_values(by='C-index', ascending=False)\n",
    "# SELECCIONAR EL MEJOR MODELO\n",
    "best_model_index = results_df['C-index'].idxmax()\n",
    "best_model = results_df.iloc[best_model_index]\n",
    "best_estimators = best_model['Estimadores']\n",
    "best_learning_rate = best_model['Learning Rate']\n",
    "best_c_index = best_model['C-index']\n",
    "print(f\"Mejor modelo: Estimadores: {best_estimators}, Learning Rate: {best_learning_rate}, C-index: {best_c_index:.4f}\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# graficar curva de supervivencia total\n",
    "def plot_survival_curve(model, X, y, title=\"Curva de Supervivencia\"):\n",
    "    # Predecir la función de supervivencia para cada individuo\n",
    "    survival_function = model.predict_survival_function(X)\n",
    "    \n",
    "    # Graficar la curva de supervivencia\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(len(survival_function)):\n",
    "        plt.step(survival_function[i].x, survival_function[i].y, where=\"post\", label=f\"Individuo {i+1}\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tiempo\")\n",
    "    plt.ylabel(\"Probabilidad de Supervivencia\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "# Graficar la curva de supervivencia total\n",
    "plot_survival_curve(gbsa, X_test, y_test, title=\"Curva de Supervivencia Total\")\n",
    "# Graficar la curva de supervivencia en funcion de la familia de vh\n",
    "def plot_survival_curve_by_family(model, X, y, family_col, title=\"Curva de Supervivencia por Familia\"):\n",
    "    # Predecir la función de supervivencia para cada individuo\n",
    "    survival_function = model.predict_survival_function(X)\n",
    "    \n",
    "    # Graficar la curva de supervivencia por familia\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    unique_families = X[family_col].unique()\n",
    "    \n",
    "    for family in unique_families:\n",
    "        family_mask = X[family_col] == family\n",
    "        for i in np.where(family_mask)[0]:\n",
    "            plt.step(survival_function[i].x, survival_function[i].y, where=\"post\", label=f\"{family} - Individuo {i+1}\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tiempo\")\n",
    "    plt.ylabel(\"Probabilidad de Supervivencia\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "# Graficar la curva de supervivencia por agencia\n",
    "plot_survival_curve_by_family(gbsa, X_test, y_test, 'FAMILIA_VH', title=\"Curva de Supervivencia por Familia\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
